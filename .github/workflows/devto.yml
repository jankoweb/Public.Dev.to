# Publish articles from posts/ to dev.to
# Requires DEVTO_API_KEY secret to be set in GitHub repository settings
# Get API key from: DEV.to → Settings → Account → DEV API Keys
# Add as GitHub Secret: DEVTO_API_KEY (note: secret won't be visible after saving)
name: Publish to dev.to

on:
  push:
    branches:
      - publish
    paths:
      - 'posts/**'

permissions:
  contents: write

jobs:
  publish:
    runs-on: ubuntu-latest
    # Skip workflow if commit is from github-actions bot (front-matter updates)
    if: github.actor != 'github-actions[bot]'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get changed and deleted posts
        id: changed
        run: |
          # Get changed/added files
          if git rev-parse HEAD~1 >/dev/null 2>&1; then
            FILES=$(git diff --name-only --diff-filter=AM HEAD~1 HEAD \
              | grep '^posts/.*\.md$' \
              | tr '\n' ' ')
            DELETED=$(git diff --name-only --diff-filter=D HEAD~1 HEAD \
              | grep '^posts/.*\.md$' \
              | tr '\n' ' ')
          else
            FILES=$(git show --name-only --pretty="" HEAD \
              | grep '^posts/.*\.md$' \
              | tr '\n' ' ')
            DELETED=""
          fi
          echo "FILES=$FILES" >> $GITHUB_OUTPUT
          echo "DELETED=$DELETED" >> $GITHUB_OUTPUT
          echo "Changed files: $FILES"
          echo "Deleted files: $DELETED"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Run include-processor
        id: include
        if: steps.changed.outputs.FILES != ''
        env:
          FILES: ${{ steps.changed.outputs.FILES }}
        run: |
          python - <<'PY'
          import os, sys, re
          files = os.environ.get('FILES','').strip()
          out_dir = 'processed_posts'
          if not files:
              sys.exit(0)
          os.makedirs(out_dir, exist_ok=True)
          processed = []
          for md in files.split():
              if not os.path.exists(md):
                  print('Skip missing:', md)
                  continue
              with open(md, 'r', encoding='utf-8') as f:
                  s = f.read()

              pattern = re.compile(r':\(\s*([^\s\)]+)(?:\s+lang=([^\)\s]+))?\s*\)')

              def repl(m):
                  rel = m.group(1)
                  lang = m.group(2)
                  base = os.path.dirname(md)
                  p = rel if os.path.isabs(rel) else os.path.normpath(os.path.join(base, rel))
                  if not os.path.exists(p):
                      print('Included file not found:', p)
                      return m.group(0)
                  ext = os.path.splitext(p)[1].lower()
                  if not lang:
                      lang_map = {'.ps1':'powershell','.sh':'bash','.js':'javascript','.ts':'typescript',
                            '.py':'python','.json':'json','.html':'html','.css':'css'}
                      lang = lang_map.get(ext, 'text')
                  with open(p,'r',encoding='utf-8') as inc:
                      code = inc.read().rstrip()
                  return f"```{lang}\n{code}\n```"

              new = pattern.sub(repl, s)
              relpath = os.path.relpath(md)
              out_path = os.path.join(out_dir, relpath)
              os.makedirs(os.path.dirname(out_path), exist_ok=True)
              with open(out_path, 'w', encoding='utf-8') as f:
                  f.write(new)
              processed.append(out_path)
              print('Wrote processed file:', out_path)

          if processed:
              gh_out = os.environ.get('GITHUB_OUTPUT')
              if gh_out:
                  with open(gh_out, 'a', encoding='utf-8') as out:
                      # Output as newline-separated list for publish-devto action
                      out.write('PROCESSED_FILES<<EOF\n')
                      out.write('\n'.join(processed))
                      out.write('\nEOF\n')
          PY

      - name: Publish articles to dev.to
        if: steps.changed.outputs.FILES != ''
        uses: sinedied/publish-devto@v2
        with:
          devto_key: ${{ secrets.DEVTO_API_KEY }}
          files: ${{ steps.include.outputs.PROCESSED_FILES }}
          conventional_commits: false

      - name: Copy front-matter updates back to original files
        if: steps.changed.outputs.FILES != ''
        run: |
          python - <<'PY'
          import os, sys, re
          
          # Get processed files directory
          out_dir = 'processed_posts'
          if not os.path.exists(out_dir):
              print("No processed files directory found")
              sys.exit(0)
          
          # Walk through processed files
          for root, dirs, files in os.walk(out_dir):
              for f in files:
                  if not f.endswith('.md'):
                      continue
                  
                  processed_path = os.path.join(root, f)
                  # Get original path by removing the out_dir prefix
                  original_path = os.path.relpath(processed_path, out_dir)
                  
                  if not os.path.exists(original_path):
                      print(f"Original file not found: {original_path}")
                      continue
                  
                  # Read both files
                  with open(processed_path, 'r', encoding='utf-8') as pf:
                      processed_content = pf.read()
                  
                  with open(original_path, 'r', encoding='utf-8') as of:
                      original_content = of.read()
                  
                  # Extract front-matter from processed file
                  processed_fm_match = re.match(r'^---\n(.*?)\n---\n', processed_content, re.DOTALL)
                  original_fm_match = re.match(r'^---\n(.*?)\n---\n', original_content, re.DOTALL)
                  
                  if not processed_fm_match or not original_fm_match:
                      print(f"Could not extract front-matter from {original_path}")
                      continue
                  
                  processed_fm = processed_fm_match.group(1)
                  original_fm = original_fm_match.group(1)
                  
                  # Extract id, date, and url from processed front-matter
                  updates = {}
                  for key in ['id', 'date', 'url']:
                      match = re.search(rf'^{key}:\s*(.+)$', processed_fm, re.MULTILINE)
                      if match:
                          updates[key] = match.group(1).strip()
                  
                  if not updates:
                      print(f"No updates found for {original_path}")
                      continue
                  
                  # Update original front-matter
                  new_fm_lines = []
                  original_fm_lines = original_fm.split('\n')
                  updated_keys = set()
                  
                  for line in original_fm_lines:
                      key_match = re.match(r'^([\w-]+):', line)
                      if key_match:
                          key = key_match.group(1)
                          if key in updates:
                              new_fm_lines.append(f"{key}: {updates[key]}")
                              updated_keys.add(key)
                          else:
                              new_fm_lines.append(line)
                      else:
                          new_fm_lines.append(line)
                  
                  # Add any new keys that weren't in original
                  for key, value in updates.items():
                      if key not in updated_keys:
                          new_fm_lines.append(f"{key}: {value}")
                  
                  new_fm = '\n'.join(new_fm_lines)
                  
                  # Replace front-matter in original content
                  original_body = original_content[original_fm_match.end():]
                  new_content = f"---\n{new_fm}\n---\n{original_body}"
                  
                  # Write back to original file
                  with open(original_path, 'w', encoding='utf-8') as of:
                      of.write(new_content)
                  
                  print(f"Updated front-matter in {original_path}")
                  for key, value in updates.items():
                      print(f"  {key}: {value}")
          PY

      - name: Commit front-matter updates
        if: steps.changed.outputs.FILES != ''
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add posts/
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "chore: update article front-matter"
            git push
          fi

      - name: Handle deleted articles
        if: steps.changed.outputs.DELETED != ''
        env:
          DELETED: ${{ steps.changed.outputs.DELETED }}
          DEVTO_API_KEY: ${{ secrets.DEVTO_API_KEY }}
        run: |
          python - <<'PY'
          import os, sys, re, json
          try:
              import urllib.request
          except ImportError:
              print("urllib not available")
              sys.exit(0)
          
          deleted = os.environ.get('DELETED', '').strip()
          api_key = os.environ.get('DEVTO_API_KEY', '').strip()
          
          if not deleted or not api_key:
              print("No deleted files or API key not set")
              sys.exit(0)
          
          # For each deleted file, try to find its ID from git history
          for md_file in deleted.split():
              if not md_file:
                  continue
              print(f"Processing deleted file: {md_file}")
              
              # Get the last version of the file from git
              try:
                  import subprocess
                  result = subprocess.run(
                      ['git', 'show', f'HEAD~1:{md_file}'],
                      capture_output=True,
                      text=True,
                      check=True
                  )
                  content = result.stdout
                  
                  # Extract ID from front matter
                  match = re.search(r'^id:\s*(\d+)\s*$', content, re.MULTILINE)
                  if match:
                      article_id = match.group(1)
                      print(f"Found article ID: {article_id}")
                      
                      # Unpublish the article on dev.to
                      url = f'https://dev.to/api/articles/{article_id}/unpublish'
                      req = urllib.request.Request(
                          url,
                          method='PUT',
                          headers={
                              'api-key': api_key,
                              'Content-Type': 'application/json'
                          }
                      )
                      
                      try:
                          response = urllib.request.urlopen(req)
                          print(f"Successfully unpublished article {article_id}")
                      except urllib.error.HTTPError as e:
                          print(f"Failed to unpublish article {article_id}: {e.code} {e.reason}")
                          if e.code == 404:
                              print("Article not found (may have been already deleted)")
                          else:
                              print(f"Response: {e.read().decode('utf-8')}")
                  else:
                      print(f"No article ID found in {md_file}")
              except subprocess.CalledProcessError as e:
                  print(f"Could not retrieve file from git: {e}")
              except Exception as e:
                  print(f"Error processing {md_file}: {e}")
          PY
